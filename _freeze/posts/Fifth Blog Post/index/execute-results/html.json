{
  "hash": "33977d3c5c55fbe5670905b8075a64a1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Probability Theory and Random Variables\"\nauthor: \"Daniel A. Udekwe\"\ndate: \"2023-11-23\"\ncategories: [data, code, analysis]\nimage: \"probability.jpg\"\n---\n\n\n\n\nThe subject of probability theory is the foundation upon which all of statistics is built, providing a means for modelling population, experiments or almost anything else that could be considered a random phenomenon. Through these models, statisticians are able to draw inferences about populations, inferences based on examination of only a part of the whole.\n\n# Introduction to Probability Theory\n\nProbability theory is a branch of mathematics concerned with the study of random phenomena and is often considered one of the fundamental pillars of machine learning. It is however a huge field to cover and very easy to get lost in, especially when being self-taught.\n\nIn the following sections, we are going to cover some fundamental aspects of probability before delving into aspects that are especially relevant to machine learning --- the random variable and the probability distribution.\n\n## Set Theory\n\nThe set $S$ of all possible outcomes of a particular experiment is called the sample space for the experiment. If the experiment consists of tossing a coin, the sample space contains two outcomes, heads and tails: thus,\n\n$$\nS = \\{H, T\\}\n$$\n\nIf, on the other hand, the experiment consists of observing the reported SAT scores of randomly selected students at a certain university, the sample space would be the set of positive integers between 200 and 800 that are multiples of ten --- that is, $S = \\{200, 210, 220, ..., 780, 790, 800 \\}$\n\nWe can classify sample spaces into two types according to the number of elements they contain. Sample spaces can be either **countable** or **uncountable**; If the elements of a sample space can be put into 1-1 correspondence with a subset of the integers, the sample space is countable. Of course, if the sample space contains only a finite number of elements, it is countable. Thus, the coin toss and SAT score sample is uncountable, since the positive real numbers cannot be put into 1-1 correspondence with the integers. If, however, we measured the reaction time to the nearest second, then the sample space would be (in seconds) $S = \\{0, 1, 2, 3, ... \\}$, which is then countable.\n\n## Events\n\nAn event is any collection of possible outcomes of an experiment that is, any subset of $S$ (including $S$ itself)\n\nLet A be an event, a subset of S. We say the event A occurs if the outcome of the experiment is the set A. When speaking of probabilities, we generally speak of the probability of an event, rather than a set. But we may use the terms interchangeably.\n\nGiven any two events (or sets) A and B, we have the following elementary set operations.\n\n**Union**: The union of A and B, written $A\\cup B$ is the set of elements that belong to either A or B or both\n\n$$\nA \\cup B = \\{x:x \\in A \\ or \\ x \\in B \\}\n$$\n\n**Intersection:** The intersection of A and B, written $A\\cap B$ is the set of elements that belong to both A and B\n\n$$\nA \\cap B = \\{x:x \\in A \\ and \\ x \\in B\\}\n$$\n\n**Complementation:** The complement of A, written $A^c$, is the set of all elements that are not in A\n\n$$\nA^c = \\{x:x \\not\\in A\\}\n$$\n\nElementary set operations can be combined, somewhat akin to the way addition and multiplication can be combined. As long as we are careful, we can treat sets as if they were numbers. We can now state the following useful properties of set operations.\n\n1.  Commutativity.\n\n    a\\. $A\\cup B = B \\cup B$,\n\n    b\\. $A \\cap B = B \\cap A$\n\n2.  Assocaiativity\n\n    a\\. $A \\cup (B\\cup C) = (A \\cup B) \\cup C$\n\n    b\\. $A \\cap (B\\cap C) = (A \\cap B) \\cap C$\n\n3.  Distribution Laws\n\n    a\\. $A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)$\n\n    b\\. $A \\cup (B\\cap C) = (A \\cup B) \\cap (A \\cup C)$\n\n4.  DeMorgan's Laws\n\n    a\\. $(A \\cup B )^C = A^C \\cap B^C$\n\n    b\\. $(A \\cap B )^C = A^C \\cup B^C$\n\n## Probability\n\nConsider the simple experiment of tossing a fair coin, so $S = \\{H, T\\}$. By a \"fair\" coin we mean a balanced coin that is equally as likely to land heads up as tails up, and hence the reasonable probability function is the one that assigns equal probabilities to heads and tails, that is\n\n$$\nP(\\{H\\}) = P(\\{T\\})\n$$\n\nSince $S = \\{H\\} \\cup \\{T\\}$, we have $P(\\{H\\} \\cup \\{T\\}) = P(\\{H\\}) + P(\\{T\\})$ and\n\n$$\nP(\\{H\\}) + P(\\{T\\}) = 1\n$$\n\nSolving the equations simultaneously shows that $P(\\{H\\}) = P(\\{T\\}) = 1/2$\n\nIn machine learning, we often deal with uncertainty and stochastic quantities, due to one of the reasons being incomplete observability --- therefore, we most likely work with sampled data.\n\nNow, suppose we want to draw reliable conclusions about the behavior of a random variable, despite the fact that we only have limited data and we simply do not know the entire population.\n\nHence, we need some kind of way to generalize from the sampled data to the population, or in other words --- we need to estimate the true data-generating process.\n\n![Estimating the data-generating process](images/data-generation.webp)\n\nUnderstanding the probability distribution, allows us to compute the probability of a certain outcome by also accounting for the variability in the results. Thus, it enables us to generalize from the sample to the population, estimate the data-generating function and predict the behavior of a random variable more accurately.\n\n# Random Variables\n\nLoosely speaking, the random variable is a variable whose value depends on the outcome of a random event. We can also describe it as a function that maps from the sample space to a measurable space (e.g. a real number).\n\nLet's assume, we have a sample space containing 4 students `{A, B, C, D}`. If we now randomly pick `student A` and measure the height in centimeters, we can think of the `random variable (H)`as the function with the input of `student`and the output of `height`as a real number.\n\n$$\nH(student) = height\n$$\n\nWe can visualize this small example like the following\n\n![An example of a random variable](images/random-variable.webp)\n\nDepending on the outcome --- which student is randomly picked --- our random variable (H) can take on different states or different values in terms of height in centimeters.\n\nA random variable can be either discrete or continuous.\n\nIf our random variable can take only a finite or countably infinite number of distinct values, then it is discrete. Examples of a discrete random variable include the number of students in a class, test questions answered correctly, the number of children in a family, etc.\n\nOur random variable, however, is continuous if between any two values of our variable are an infinite number of other valid values. We can think of quantities such as pressure, height, mass, and distance as examples of continuous random variables.\n\nWhen we couple our random variable with a probability distribution we can answer the following question: How likely is it for our random variable to take a specific state? Which is basically the same as asking for the probability.\n\nNow, we are left with one question that remains--- what is a probability distribution?\n\n# Probability Distribution\n\nThe description of how likely a random variable takes one of its possible states can be given by a probability distribution. Thus, the probability distribution is a mathematical function that gives the probabilities of different outcomes for an experiment.\n\nMore generally it can be described as the function\n\n$$\nP:A \\rightarrow R\n$$\n\nwhich maps an input space A --- related to the sample space --- to a real number, namely the probability.\n\nFor the above function to characterize a probability distribution, it must follow all of the **Kolmogorov axioms:**\n\n1.  **Non**-negativity\n\n2.  No probability exceeds 1\n\n3.  Additivity of any countable disjoint (mutually exclusive) events\n\nThe way we describe a probability distribution depends on whether the random variable is discrete or continuous, which will result in a probability mass or density function respectively.\n\n## **Probability Mass Function**\n\nThe probability mass function (PMF) describes the probability distribution over a discrete random variable. In other terms, it is a function that returns the probability of a random variable being exactly equal to a specific value.\n\nThe returned probability lies in the range \\[0, 1\\] and the sum of all probabilities for every state equals one.\n\nLet's imagine a plot where the x-axis describes the states and the y-axis shows the probability of a certain state. Thinking this way allows us to envision the probability or the PMF as a barplot sitting on top of a state.\n\n![An example of a uniform PMF](images/probability-mass-function.webp)\n\nIn the following, we will learn about three common discrete probability distributions: The Bernoulli, binomial and geometric distribution.\n\n### Bernoulli Distribution\n\nNamed after the Swiss mathematician Jacob Bernoulli, the Bernoulli distribution is a discrete probability distribution of a single binary random variable, which either takes the value 1 or 0.\n\nLoosely speaking, we can think of the Bernoulli distribution as a model giving the set of possible outcomes for a single experiment, that can be answered with a simple yes-no question.\n\nMore formally the function can be stated as the following equation\n\n$$\nf(k;p) =     \\begin{dcases}\n        q = 1-p & if \\ k = 0 \\\\\n        q & if \\ k = 1 \\\\\n    \\end{dcases}\n$$\n\n$$\nf(k;p) = p^k(1-p)^{1-k} \\ for \\ k \\in \\{0,1\\}\n$$\n\nwhich basically evaluates to `p if k=1` or to `(1-p) if k=0`. Thus, the Bernoulli distribution is parametrized by just a `single parameter p`.\n\nSuppose, we toss a fair coin once. The probability of obtaining heads is `P(Heads) = 0.5`. Visualizing the PMF we get the following plot:\n\n![](images/bernoulli-distribution.webp)\n\nSince the Bernoulli Distribution models only a single trial, it can also be viewed as a special case of the binomial distribution\n\n### Binomial Distribution\n\nThe binomial distribution describes the discrete probability distribution of the number of successes in a sequence of *n* independent trials, each with a binary outcome. The success or failure is given by the probability *p* or *(1-p)* respectively*.*\n\nThus, the binomial distribution is parametrized by the parameters\n\n$$\nn \\in N, \\ p \\in [0,1]\n$$\n\nMore formally the binomial distribution can be expressed with the following equation:\n\n$$\nf(k;n,p) = {n \\choose k} p^k(1-p)^{n-k}\n$$\n\nThe success of *k* is given by the probability *p* to the power of *k,* whereas the probability of failure is defined by *(1-p)* to the power of *n* minus *k*, which is basically the number of trials minus the one trial where we get *k*.\n\nSince the event of success *k* can occur anywhere in *n* trials, we have ***\"n choose k\"*** ways to distribute the success.\n\nLet's pick up our coin-tossing example from before and build on it.\n\nNow, we are going to flip the fair coin three times, while being interested in the random variable describing the number of heads obtained.\n\n![Number of heads in three coin flips](images/binomial-distribution.webp)\n\nIf we want to compute the probability of the coin coming up as heads two times, we can simply use the equation from before and pluck in the values.\n\n$$\nP(2) = {3 \\choose 2} p^2 (1-p)^{3-2}\n$$\n\n$$\nP(2) = 3(0.5)^2(0.5)^1\n$$\n\n$$\nP(2) = 0.375\n$$\n\nwhich results in a probability `P(2) = 0.375`. If we proceed in the same way for the remaining probabilities, we get the following distribution:\n\n![](images/binomial-distribution-2.webp)\n\n### Geometric Distribution\n\nSuppose, we are interested in the number of times we have to flip a coin until it comes up heads for the first time.\n\nThe geometric distribution gives the probability of the first success occurrence, requiring *n* independent trials, with a success probability of *p*.\n\nMore formally it can be stated as\n\nwhich computes the probability of the number of trials needed up to and including the success event.\n\nThe following assumptions need to be true, in order to calculate the geometric distribution:\n\n1.  Independence\n\n2.  For each trial, there are only two possible outcomes\n\n3.  The probability of success is the same for every trial\n\nLet's visualize the geometric distribution by answering the question for the probability of the number of trials needed for the coin to come up heads for the first time.\n\n![The geometric distribution until first head](images/geometric.jpg)\n\n### Gaussian Distribution\n\nThe Gaussian distribution is often considered a sensible choice to represent a real-valued random variable, whose distribution is unknown.\n\nThis is mainly due to the central limit theorem, which, loosely speaking, states that the average of many independent random variables with finite mean and variance is itself a random variable --- which is normally distributed as the number of observations increases.\n\nThis is especially useful since it allows us to model complicated systems as Gaussian distributed, even if the individual parts follow a more complicated structure or distribution.\n\nAnother reason it is a common choice for modeling a distribution over a continuous variable is the fact that it inserts the least amount of prior knowledge.\n\nMore formally, the Gaussian distribution can be stated as\n\n$$\nN (x: \\mu, \\sigma^2) = \\sqrt\\frac{1}{2\\pi\\sigma^2}exp(-\\frac{1}{2\\sigma^2}(x-\\mu)^2)\n$$\n\nwhere the parameter *µ* is the mean and *σ²* describes the variance.\n\nIn simple terms, the mean will be responsible for defining the central peak of the bell-shaped distribution, whereas the variance or the standard deviation defines its width.\n\nWe can visualize the normal distribution as the following:\n\n![An example of a Gaussian distribution](images/gaussian-distribution.webp)\n\n## Probability Density Function\n\nIn the earlier sections, we learned that a random variable can either be discrete or continuous. If it is discrete, we can describe the probability distribution with a probability mass function.\n\nNow, we are dealing with continuous variables --- hence, we need to describe the probability distribution with a probability density function (PDF).\n\nThe PDF, contrary to the PMF, does not give the probability of a random variable taking a specific state directly. Instead, it describes the probability of landing inside an infinitesimal region. In other terms, the PDF describes the probability of a random variable lying between a particular range of values.\n\nIn order to find the actual probability mass, we need to integrate, which yields the area under the density function but above the x-axis.\n\n![An example of a probability density function](images/density-function.webp)\n\nThe probability density function must be non-negative and its integral needs to be 1.\n\n$$\n(1) \\ \\ p(x) \\ge 0\n$$\n\n$$\n(2) \\ \\ \\int p(x) \\delta x = 1\n$$\n\nOne of the most common continuous probability distributions is the gaussian or normal distribution.\n\n# Applications in Machine Learning\n\n## Bayesian Inference\n\nBayesian inference is a way of making statistical inferences in which the statistician assigns subjective probabilities to the distributions that could generate the data. These subjective probabilities form the so-called prior distribution.\n\nAfter the data is observed, [Bayes' rule](https://www.statlect.com/fundamentals-of-probability/Bayes-rule) is used to update the prior, that is, to revise the probabilities assigned to the possible data generating distributions. These revised probabilities form the so-called posterior distribution.\n\nThis lecture provides an introduction to Bayesian inference and discusses a simple example of inference about the mean of a normal distribution.\n\n### **The likelihood**\n\nThe first building block of a parametric Bayesian model is the likelihood\n\nThe likelihood is equal to the probability density of x when the parameter of the data generating distribution is equal to $\\theta$\n\nFor the time being, we assume that and are [continuous](https://www.statlect.com/glossary/absolutely-continuous-random-variable). Later, we will discuss how to relax this assumption.\n\n### **The prior**\n\nThe second building block of a Bayesian model is the prior\n\n$$\np(\\theta)\n$$\n\nThe prior is the subjective probability density assigned to the parameter\n\n### **The posterior**\n\nAfter observing the data , we use Bayes' rule to update the prior about the parameter :\n\nThe conditional density is called posterior distribution of the parameter.\n\nBy using the formula for the marginal density derived above, we obtain\n\nThus, the posterior depends on the two distributions specified by the statistician, the prior and the likelihood .\n\nExample\n\n::: {#03e6fdac .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta, binom\n\n# Set up prior distribution\na = 0.5  # alpha parameter\nb = 0.5  # beta parameter\nprior = beta(a, b)  # create Beta distribution object\n\n# Generate some fake data\nn = 100  # number of trials\nk = 40   # number of successes\ndata = binom.rvs(1, k/n, size=n)  # generate binary data from binomial distribution\n\n# Compute posterior distribution\na_post = a + np.sum(data)  # update alpha parameter\nb_post = b + n - np.sum(data)  # update beta parameter\nposterior = beta(a_post, b_post)  # create updated Beta distribution object\n\n# Compute credible intervals\nCI_95 = beta.ppf([0.025, 0.975], a_post, b_post)  # compute 95% credible interval\n\n# Plot prior and posterior distributions\nx = np.linspace(0, 1, 1000)\nprior_pdf = prior.pdf(x)\nposterior_pdf = posterior.pdf(x)\n\nplt.plot(x, prior_pdf, 'b--', linewidth=2)\nplt.plot(x, posterior_pdf, 'r-', linewidth=2)\nplt.ylim([0, max(posterior_pdf)*1.1])\nplt.legend(['Prior', 'Posterior'])\nplt.xlabel('p/(1-p)')\nplt.ylabel('Density')\nplt.title('Bayesian Analysis of p/(1-p)')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=576 height=449}\n:::\n:::\n\n\n## Markov Chain Monte Carlo (MCMC)\n\nThere are several Bayesian models that allow us to compute the posterior distribution of the parameters analytically. However, this is often not possible.\n\nWhen an analytical solution is not available, Markov Chain Monte Carlo (MCMC) methods are commonly employed to derive the posterior distribution numerically.\n\nMCMC methods are [Monte Carlo methods](https://www.statlect.com/asymptotic-theory/Monte-Carlo-method) that allow us to generate large samples of correlated draws from the posterior distribution of the parameter vector by simply using the proportionality\n\nThe [empirical distribution](https://www.statlect.com/asymptotic-theory/empirical-distribution) of the generated sample can then be used to produce [plug-in estimates](https://www.statlect.com/asymptotic-theory/plug-in-principle) of the quantities of interest.\n\nSee the lecture on [MCMC methods](https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo) for more details.\n\n::: {#33e51505 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Define the target distribution\ndef target_dist(x):\n    return np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)\n\n# Define the proposal distribution (normal distribution)\ndef prop_dist(x, sigma):\n    return np.random.normal(x, sigma)\n\n# Set the initial state and other parameters\nx0 = 0\nnum_samples = 10000\nburn_in = 1000\nsigma = 1\n\n# Initialize the Markov chain\nx = x0\n\n# Generate samples using the Metropolis-Hastings algorithm\nsamples = np.zeros(num_samples)\nfor i in range(num_samples + burn_in):\n    # Generate a proposal\n    x_prop = prop_dist(x, sigma)\n\n    # Compute the acceptance probability\n    alpha = min(1, target_dist(x_prop) / target_dist(x))\n\n    # Decide whether to accept the proposal\n    if np.random.rand() < alpha:\n        x = x_prop\n\n    # Save the sample after the burn-in period\n    if i > burn_in:\n        samples[i - burn_in] = x\n\n# Plot the histogram of the samples and the target distribution\nplt.hist(samples, bins=30, density=True, alpha=0.5)\nx_vals = np.linspace(-5, 5, 100)\nplt.plot(x_vals, target_dist(x_vals), 'r-', linewidth=2)\nplt.xlabel('x')\nplt.ylabel('Probability density')\nplt.legend(['Samples', 'Target distribution'])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=597 height=429}\n:::\n:::\n\n\nIllustrations are obtained from here[^1]\n\n[^1]: <https://towardsdatascience.com/>\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}