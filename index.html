<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Daniel A. Udekwe </title> <meta name="author" content="Daniel A. Udekwe"> <meta name="description" content="Daniel Udekwe's Personal Website "> <meta name="keywords" content="Quantum Computing, Virtual Reality, Deep Learning, Robotics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%94%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://daniel-udekwe.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">Media </a> </li> <li class="nav-item "> <a class="nav-link" href="/project/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/_pages/talks/"> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Daniel</span> A. Udekwe </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profile-480.webp 480w,/assets/img/profile-800.webp 800w,/assets/img/profile-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/profile.jpg?64fc483fd3ff92bd553f6b0b9387ec72" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="profile.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Office E25A, FLVC Building</p> <p>1753 W Paul Dirac Dr,</p> <p>Tallahassee, Florida </p> </div> </div> <div class="clearfix"> <p>I am a doctoral researcher in Civil Engineering at the <a href="https://eng.famu.fsu.edu" rel="external nofollow noopener" target="_blank">FAMU-FSU College of Engineering</a>, working under the supervision of <a href="https://eng.famu.fsu.edu/cee/people/guo" rel="external nofollow noopener" target="_blank">Qianwen (Vivian) Guo</a>. My research spans <strong>transportation engineering</strong>, with a focus on human‚Äìmachine interaction and emerging computational methods that advance how transportation systems are designed and evaluated.</p> <p>I hold a B.Eng. in Electrical Engineering, and my academic background reflects a strongly interdisciplinary approach to problem-solving. I am currently exploring the potential of quantum computing and virtual reality to support next-generation tools and methodologies in transportation network design.</p> <p><span style="color:red; font-weight:bold;">I am on the job market in the academic year 2026-27, see my <a href="https://daniel-udekwe.github.io/assets/pdf/danielUdekweCV_A.pdf">CV</a> here.</span></p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 16, 2025</th> <td> I will be delivering a lectern session ‚ÄúEnhancing Accessibility for Elder Users: A Quantum-Inspired Bilevel Optimization Framework for Transit Route Design‚Äù at the <a href="https://trb-annual-meeting.nationalacademies.org/" rel="external nofollow noopener" target="_blank">TRB 105th Annual Meeting</a>, at (01/13, 8:00 - 9:45 pm). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 16, 2025</th> <td> I will give a poster presentation titled ‚ÄúVRISE: A Virtual Reality¬†Platform for Immersive and Interactive Surveying Education‚Äù at the <a href="https://trb-annual-meeting.nationalacademies.org/" rel="external nofollow noopener" target="_blank">TRB 105th Annual Meeting</a>, at (01/13, 4:00 - 5:45 pm). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 11, 2025</th> <td> I will give a poster presentation titled ‚ÄúQuantifying the Impact of Sun Glare on Crash Risk in Leon County, Florida‚Äù at the <a href="https://www.linkedin.com/posts/fpsite-transportationengineering-scholarship-share-7390137738643120128-c0Vb?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAABfkvkYBLNkvHljTiKthByP0jjgENtqDJzw" rel="external nofollow noopener" target="_blank">2025 FPSITE Poster Competition</a>, at (11/13, 3:00 -5:00 pm, FLVC Room C01). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 01, 2025</th> <td> I will give a demonstration on the applications of virtual reality in engineering at the <a href="https://www.facebook.com/bondelementary/photos/-get-ready-for-a-night-of-discovery-and-fun-bond-elementary-school-is-hosting-st/1438507438282872/" rel="external nofollow noopener" target="_blank">Bond Elementary School STEAM Night</a>, at (11/13, 5:30 pm, 2204 Saxon Street, Tallahassee (In the Eagles Nest Cafeteria)). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 01, 2025</th> <td> I will give a demonstration on the applications of virtual reality in engineering at the <a href="https://www.tallahassee.com/story/news/local/2025/11/07/tsc-to-host-14th-annual-tallahassee-science-festival-for-the-community/87086404007/" rel="external nofollow noopener" target="_blank">14th Annual Tallahassee Science Festival</a>, at (11/8, 10:00 - 2:00 pm, Kleman Plaza, Downtown Tallahassee). </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ball_plate_1-480.webp 480w,/assets/img/publication_preview/ball_plate_1-800.webp 800w,/assets/img/publication_preview/ball_plate_1-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/ball_plate_1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ball_plate_1.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="okafor2021heuristic" class="col-sm-8"> <div class="title">Heuristic and deep reinforcement learning-based PID control of trajectory tracking in a ball-and-plate system</div> <div class="author"> Emmanuel Okafor ,¬† Daniel Udekwe ,¬† Yusuf Ibrahim , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Muhammed Bashir Mu‚Äôazu, Ekene Gabriel Okafor' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Journal of Information and Telecommunication</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The manual tuning of controller parameters, for example, tuning proportional integral derivative (PID) gains often relies on tedious human engineering. To curb the aforementioned problem, we propose an artificial intelligence-based deep reinforcement learning (RL) PID controller (three variants) compared with genetic algorithm-based PID (GA-PID) and classical PID; a total of five controllers were simulated for controlling and trajectory tracking of the ball dynamics in a linearized ball-and-plate (ùêµ&amp;ùëÉ) system. For the experiments, we trained novel variants of deep RL-PID built from a customized deep deterministic policy gradient (DDPG) agent (by modifying the neural network architecture), resulting in two new RL agents (DDPG-FC-350-R-PID &amp; DDPG-FC-350-E-PID). Each of the agents interacts with the environment through a policy and a learning algorithm to produce a set of actions (optimal PID gains). Additionally, we evaluated the five controllers to assess which method provides the best performance metrics in the context of the minimum index in predictive errors, steady-state-error, peak overshoot, and time-responses. The results show that our proposed architecture (DDPG-FC-350-E-PID) yielded the best performance and surpasses all other approaches on most of the evaluation metric indices. Furthermore, an appropriate training of an artificial intelligence-based controller can aid to obtain the best path tracking.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">okafor2021heuristic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Heuristic and deep reinforcement learning-based PID control of trajectory tracking in a ball-and-plate system}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Okafor, Emmanuel and Udekwe, Daniel and Ibrahim, Yusuf and Bashir Mu'azu, Muhammed and Okafor, Ekene Gabriel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Information and Telecommunication}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{179--196}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Taylor \&amp; Francis}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ball_plate_2-480.webp 480w,/assets/img/publication_preview/ball_plate_2-800.webp 800w,/assets/img/publication_preview/ball_plate_2-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/ball_plate_2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ball_plate_2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="udekwe2024comparing" class="col-sm-8"> <div class="title">Comparing actor-critic deep reinforcement learning controllers for enhanced performance on a ball-and-plate system</div> <div class="author"> Daniel Udekwe ,¬† Ore-ofe Ajayi ,¬† Osichinaka Ubadike , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Kumater Ter, Emmanuel Okafor' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Expert systems with applications</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The optimization of controller parameters remains an ongoing challenge in the field of control system applications. This study introduces a novel approach involving the creation of custom actor-critic deep reinforcement learning (DRL) based PID controllers. These controllers are designed with the goal of achieving adaptive tuning, precise trajectory tracking, and stability in a ball-and-plate system. To achieve this objective, multiple actor-critic reinforcement learning agents were developed using different learning algorithms: Soft actor critic (SAC), deep deterministic policy gradient (DDPG), and twin delayed deep deterministic policy gradient (TD3). These agents incorporate multilayer-perceptron (MLP) policy learning algorithms in both the actor and critic network architectures, employing non-linear activation functions. This enables them to fine-tune PID control parameters within an infinite search space. Additionally, a custom reward function derived from the system‚Äôs environment was integrated into the learning process. The performance of the proposed methods was compared against a benchmark method, specifically, an existing deep reinforcement learning controllers reported in the literature. The evaluation of these controllers and other approaches was based on error metrics and time response analysis. Results demonstrate that the proposed controller denoted as SAC-PID(5) excelled in trajectory tracking and outperformed other methods. It exhibited minimal predictive errors and the shortest time responses in the majority of experiments. This highlights the significance of designing a customized SAC agents with appropriate network architecture, which positively impacts the learning process for intelligent tuning of controllers for classical control systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">udekwe2024comparing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Comparing actor-critic deep reinforcement learning controllers for enhanced performance on a ball-and-plate system}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Udekwe, Daniel and Ajayi, Ore-ofe and Ubadike, Osichinaka and Ter, Kumater and Okafor, Emmanuel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert systems with applications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{245}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{123055}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hri_1-480.webp 480w,/assets/img/publication_preview/hri_1-800.webp 800w,/assets/img/publication_preview/hri_1-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/hri_1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hri_1.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="udekwe2025human" class="col-sm-8"> <div class="title">Human robot interaction for agricultural Tele-Operation, using virtual Reality: A feasibility study</div> <div class="author"> Daniel Udekwe ,¬† and¬† Hasan Seyyedhasani </div> <div class="periodical"> <em>Computers and Electronics in Agriculture</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>With the increasing demand for efficient and sustainable agricultural practices, the automation of tasks such as crop inspection and harvesting has become a critical endeavor. However, the complex and dynamic nature of agricultural environments poses challenges for conventional methods that are fully autonomous or those relying on traditional interfaces. To address these challenges, we propose a solution that leverages the capabilities of Virtual Reality (VR) to provide operators with an intuitive and immersive control experience. This paper introduces a novel method for tele-operating a robotic system in agriculture using VR technology. By integrating a VR device with SteamVR and Unity 3D, users can control a mobile robotic module over a local network or the internet using VR hand controllers and a headset. In order to validates the system feasibility, we case studied two agricultural operations in lab settings: leaf inspection and crop harvesting. The results of this study were evaluated based on the cycle completion time (CCT) and the success rate of robot-plant interaction (RPI). For fruit harvesting, with a sample size (N) = 5, the mean CCT was approximately 18 s, with a standard deviation of nearly 5 s, indicating an improvement compared to existing autonomous systems in the literature. Additionally, in the leaf inspections, the mean CCT resulted in approximately 26 s with the standard deviation of nearly 6 s with the same sample size. The RPI success rate reached up to 90 % in the fruit harvesting practices. And in leaf inspection practices, this metric averaged two attempts per diseased leaf, 50 %, to grasp it and bring it to the operator‚Äôs attention. Through this study, the combination of consumer-grade VR technologies with a mobile robotic manipulation system highlights the system‚Äôs promise in improving remote agricultural tasks, especially in response to labor scarcity and improving farmworker efficiency.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">udekwe2025human</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Human robot interaction for agricultural Tele-Operation, using virtual Reality: A feasibility study}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Udekwe, Daniel and Seyyedhasani, Hasan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers and Electronics in Agriculture}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{228}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{109702}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/hri_2-480.webp 480w,/assets/img/publication_preview/hri_2-800.webp 800w,/assets/img/publication_preview/hri_2-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/hri_2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="hri_2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="udekwe2025virtual" class="col-sm-8"> <div class="title">Virtual Reality-Enabled remote Human-Robot interaction for strawberry cultivation in greenhouses</div> <div class="author"> Daniel Udekwe ,¬† and¬† Hasan Seyyedhasani </div> <div class="periodical"> <em>Computers and Electronics in Agriculture</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>This paper investigates the application of a VR-controlled robotic system for yield monitoring in strawberry farming within a greenhouse environment. The study aims to evaluate the effectiveness of the system in identifying and counting ripe strawberries, categorized by size (small and large) and variety (Seascape and Albion), and compares with the obtained results by an onsite human expert. We designed experiments, in a controlled environment agriculture center, and conducted in two trials. The yield monitoring performance of the developed robotic system was evaluated based on two primary metrics of cycle completion times and fruit detection accuracy, 32 strawberry plants which grew 336 ripe fruits. In the first experiment, the system achieved detection rates of 63 % for small strawberries and 72 % for large strawberries, with cycle completion times ranging from 12.5 to 16 s. In the second experiment, improvements were observed, with detection rates increasing to 74 % for both sizes and cycle completion times reduced to between 11.9 and 15.7 s. The developed robotic system demonstrated high accuracy and efficiency, particularly with larger strawberries. However, some limitations were identified, including challenges related to occlusion. These findings suggest that while the VR-controlled robotic system has the potential to complement and even surpass traditional yield monitoring methods managed by human experts, further refinements are necessary. Future research should focus on optimizing the system‚Äôs performance and adapting the system to broader applications in agriculture.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">udekwe2025virtual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Virtual Reality-Enabled remote Human-Robot interaction for strawberry cultivation in greenhouses}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Udekwe, Daniel and Seyyedhasani, Hasan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers and Electronics in Agriculture}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{237}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{110567}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/vrise-480.webp 480w,/assets/img/publication_preview/vrise-800.webp 800w,/assets/img/publication_preview/vrise-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/vrise.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="vrise.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="udekwe2025vrise" class="col-sm-8"> <div class="title">Vrise: A virtual reality platfrom for immersive and interactive surveying education</div> <div class="author"> Daniel Udekwe ,¬† Dimitrios Bolkas ,¬† Eren Erman Ozguven , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ren Moses, Qianwen Guo' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2507.22810</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Surveying is a core component of civil engineering education, requiring students to engage in hands-on spatial measurement, instrumentation handling, and field-based decision-making. However, traditional instruction often poses logistical and cognitive challenges that can hinder accessibility and student engagement. While virtual laboratories have gained traction in engineering education, few are purposefully designed to support flexible, adaptive learning in surveying. To address this gap, we developed Virtual Reality for Immersive and Interactive Surveying Education (VRISE), an immersive virtual reality laboratory that replicates ground-based and aerial surveying tasks through customizable, accessible, and user-friendly modules. VRISE features interactive experiences such as differential leveling with a digital level equipment and waypoint-based drone navigation, enhanced by input smoothing, adaptive interfaces, and real-time feedback to accommodate diverse learning styles. Evaluation across multiple user sessions demonstrated consistent gains in measurement accuracy, task efficiency, and interaction quality, with a clear progression in skill development across the ground-based and aerial surveying modalities. By reducing cognitive load and physical demands, even in tasks requiring fine motor control and spatial reasoning, VRISE demonstrates the potential of immersive, repeatable digital environments to enhance surveying education, broaden participation, and strengthen core competencies in a safe and engaging setting.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">udekwe2025vrise</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vrise: A virtual reality platfrom for immersive and interactive surveying education}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Udekwe, Daniel and Bolkas, Dimitrios and Ozguven, Eren Erman and Moses, Ren and Guo, Qianwen}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2507.22810}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/qrestore-480.webp 480w,/assets/img/publication_preview/qrestore-800.webp 800w,/assets/img/publication_preview/qrestore-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/qrestore.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="qrestore.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="udekwe2025q" class="col-sm-8"> <div class="title">Q-restore: quantum-driven framework for resilient and equitable transportation network restoration</div> <div class="author"> Daniel Udekwe ,¬† Ruimin Ke ,¬† Jiaqing Lu , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Qian-wen Guo' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2501.11197</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-altmetric-id="true"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Efficient and socially equitable restoration of transportation networks post disasters is crucial for community resilience and access to essential services. The ability to rapidly recover critical infrastructure can significantly mitigate the impacts of disasters, particularly in underserved communities where prolonged isolation exacerbates vulnerabilities. Traditional restoration methods prioritize functionality over computational efficiency and equity, leaving low-income communities at a disadvantage during recovery. To address this gap, this research introduces a novel framework that combines quantum computing technology with an equity-focused approach to network restoration. Optimization of road link recovery within budget constraints is achieved by leveraging D Wave‚Äôs hybrid quantum solver, which targets the connectivity needs of low, average, and high income communities. This framework combines computational speed with equity, ensuring priority support for underserved populations. Findings demonstrate that this hybrid quantum solver achieves near instantaneous computation times of approximately 8.7 seconds across various budget scenarios, significantly outperforming the widely used genetic algorithm. It offers targeted restoration by first aiding low-income communities and expanding aid as budgets increase, aligning with equity goals. This work showcases quantum computing‚Äôs potential in disaster recovery planning, providing a rapid and equitable solution that elevates urban resilience and social sustainability by aiding vulnerable populations in disasters.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">udekwe2025q</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Q-restore: quantum-driven framework for resilient and equitable transportation network restoration}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Udekwe, Daniel and Ke, Ruimin and Lu, Jiaqing and Guo, Qian-wen}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2501.11197}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%64%61%75%32%34@%66%73%75.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-1771-5320" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=PkqoFXIAAAAJ&amp;hl=en" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Daniel-Udekwe/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/daniel-udekwe" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/daniel-udekwe-19a2bbb2" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Contact me for collaboration, research and consultancy projects. </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> ¬© Copyright 2025 Daniel A. Udekwe. <br> <br> <em>"I find that I don't understand things unless I try to program them."</em> <l> <br> ‚ÄîDonald E. Knuth <br> <br> Last updated: November 20, 2025. </l> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>